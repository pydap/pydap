{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e28f3ceb-a7c9-4d96-aed5-f3e3b7bbf8b8",
   "metadata": {},
   "source": [
    "# PyDAP as a client\n",
    "\n",
    "\n",
    "`PyDAP` can be used to \\\"lazily\\\"  inspect and retrieve remote data from any of the thousands of scientific datasets available on the internet on [OPeNDAP](http://www.opendap.org/) data servers, allowing the user to manipulate a `Dataset` as if it were stored locally, only downloading on-the-fly when necessary. In order to transmit data from the Server to the Client, `both server and client must agree on a way to represent data`: **is it an array of integers?**, **a multi-dimensional grid?** In order to do this, a DAP protocol defines a **data model** that, in theory, should be able to represent any existing (scientific) dataset.\n",
    "\n",
    "```{note}\n",
    "**Why is it important to understand the data type covered by each protoocl?** OPeNDAP servers that implement `DAP2` and `DAP4` are written in `C/C++` and `Java`, and which means PyDAP users MUST be aware of the atomic types that such servers are compatible with.\n",
    "```\n",
    "\n",
    "There are broadly `two DAP Data Models`: [DAP2](https://zenodo.org/records/10794666) and [DAP4](https://opendap.github.io/dap4-specification/DAP4.html). From the client perspective, these two have slight differences so we provide a brief overview of the two below \n",
    "\n",
    "\n",
    "### DAP4 data model\n",
    "\n",
    "The DAP4 data model is close to a _superset_ of the older DAP2 model except that `Grids` are no longer part of the DAP4 data model (see [Figure 1]). However, since the `Grid` datatype is a DAP2 object (as opposed to a `netCDF/HDF` object), a _Grid object in DAP2 CAN be represented in DAP4_. This means that any dataset that is represented by the DAP2 data model (and say made available by a TDS/Hyrax server) can be fully represented in DAP4. However, DAP4 types and objects (like `Groups`, and `Int64`) served by a remote Hyrax/TDS data server cannot be represented in DAP2, and pydap will receive DAP responses missing those data types.\n",
    "\n",
    "To learn more about the DAP4 specification, check the [DAP4 official documentation](https://opendap.github.io/dap4-specification/DAP4.html) written jointly by Unidata and OPeNDAP, Inc back in 2016.\n",
    "\n",
    "\n",
    "\n",
    "![Figure1](/images/DAP4vsDAP2.png)\n",
    "\n",
    "**Figure 1**. Comparison between DAP2 and DAP4 data models and responses.\n",
    "\n",
    "PyDAP aims at covering all of the DAP2 and DAP4 data models, broadly speaking, and so it covers the following DAP Objects:\n",
    "\n",
    "* Groups\n",
    "* Gridded Arrays.\n",
    "* Sequences (Tabular data)\n",
    "* Structures.\n",
    "\n",
    "* All but `Opaque` and `Enum` atomic types (all others types can be represented by numpy array data).\n",
    "\n",
    "When opening a remote URL `PyDAP` will create a `Dataset` object which acts like the `root` directly. `PyDAP`'s `Dataset` can then contain multiple data types, which may be `nested`. Since `PyDAP` approaches full support of the `DAP4` model, it supports `Groups` and nested `Groups`, which may themselves hold other data types, and other nested `PyDAP` objects named above.\n",
    "\n",
    "## Groups\n",
    "\n",
    "Groups are largely a feature of `HDF5/NetCDF4` file format models. Many remote datasets (e.g. from NASA made accessible by Hyrax data servers) may contain one or more `Groups`, some of them nested. Due to the complicate spec of the HDF data model, the `DAP4` specification follows closely the `netCDF4` model. This means there are no cyclic `Groups`. Instead, there is always a root, and each `Group` has a single parent `Group`.\n",
    "\n",
    "To read data from a remote DAP4 server, you MUST set `open_url(..., protocol='dap4')`.\n",
    "\n",
    "\n",
    "Consider the following example:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2665c59-2371-4653-9691-a017b781c75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydap.client import open_url\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e0bad-74e4-4411-a643-b66508b6e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = open_url('http://test.opendap.org:8080/opendap/atlas03/ATL03_20181228015957_13810110_003_01.h5', protocol='dap4')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dda830-3dfa-4b2d-991d-9e72748096ae",
   "metadata": {},
   "source": [
    "`print(dataset)` only returns the elements within the root directory. In `DAP4`, one can navigate the dataset as if it were a POSIX filesystem, and inspect the variables within a (nested) group. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9cbcd1-bc6e-48b0-9593-f748ba6205fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['gt1r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad91b50-19d6-429f-8be0-f4fbb83ff9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['/gt1r/bckgrd_atlas'].tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0d26d2-9518-4560-a867-541a2828b010",
   "metadata": {},
   "source": [
    "We take a look at the variable `bckgrd_int_height` and its `dimensions`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e0b2ac-44aa-4bcc-b362-fc178880c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['/gt1r/bckgrd_atlas/bckgrd_int_height'].attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f20b9ad-6a0e-4cda-a8d8-8d4fecdffd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['/gt1r/bckgrd_atlas/bckgrd_int_height'].dimensions # dimensions of the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59420507-41de-4bd6-a91e-f41fa46ff259",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['/gt1r/bckgrd_atlas'].dimensions # Dimension of the Group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42983cac-3b39-429c-942a-db2934b309c1",
   "metadata": {},
   "source": [
    "```{note}\n",
    "The `dimension` `delta_time` is defined at the `Group` level, with a name relative to the (nested) `Group:/gt1r/bckgrd_atlas`. But when inspecting a variable array that list `delta_time` as its dimension, it lists `delta_time` with its Fully Qualifying Name (FQN)  \n",
    "```\n",
    "\n",
    "`Fully Qualifying Names` are an important feature of the DAP4 data model, avoiding name clashing across Groups. To read more about Qualifying Names, we refer you to the official [DAP4 Specification](https://opendap.github.io/dap4-specification/DAP4.html#_fully_qualified_names).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5714273-829c-4466-a814-a3940fb3ee19",
   "metadata": {},
   "source": [
    "Attempting to read this dataset from a DAP4 server may result in an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635f0b90-016b-42c9-bdc7-0bcdecae7dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "try:\n",
    "    open_url('http://test.opendap.org:8080/opendap/atlas03/ATL03_20181228015957_13810110_003_01.h5', protocol='dap2')\n",
    "except:\n",
    "    print(\"Your request was for a response that uses the DAP2 data model. This dataset contains variables whose data type is not compatible with that data model, causing this request to FAIL. To access this dataset ask for the DAP4 binary response encoding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8771a2da-3c16-4818-b137-e0445145dc9a",
   "metadata": {},
   "source": [
    "In the case above, a variable is of `Int64` (atomic) type, which causes the error. However, if instead the attribute is a type that is not supported by DAP2 model, the server will not raise an `HTTPError`, and `PyDAP` will download an `incomplete` dataset (with missing attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e7fc8d-75bd-4bb8-b2c2-8f60f78ae0a3",
   "metadata": {},
   "source": [
    "## Arrays / Grids\n",
    "\n",
    "Let\\'s start by accessing `Gridded Array`, i.e., data that is stored as a regular multidimensional array. Here\\'s a simple example where we access the [COADS](https://icoads.noaa.gov/) climatology from the official `OPeNDAP test server`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfad6b6-08b7-4132-bc49-57bede693d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = open_url('http://test.opendap.org/dap/data/nc/coads_climatology.nc', protocol='dap4') # dap2 is the default\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392ddb21-93ce-4c94-9e94-c10d43f96154",
   "metadata": {},
   "source": [
    "Here we used the `pydap.client.open_url` function to open an `OPeNDAP` URL specifying the location of the dataset. When we access the remote\n",
    "dataset the function returns a `DatasetType` object, which is a fancy dictionary that stores other variables. We can\n",
    "check the names of the store variables like we would do with a Python dictionary:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1d2150-c7d1-4982-8ef6-41d72dc08883",
   "metadata": {},
   "source": [
    "Another useful way to inspect the dataset is the `.tree()` method, which provides an in-depth inspection of your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec12e1-1505-4e59-b7bc-8907e87508b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c46eec-ce93-47ce-9d1d-5f110a8262de",
   "metadata": {},
   "source": [
    "```{note}\n",
    "No data has been downloaded yet. \n",
    "```\n",
    "\n",
    "Let\\'s work with the `SST` variable; we can \\\"lazily\\\" reference it using the usual dictionary syntax of `dataset['SST']`, or `dataset.SST`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7a1918-ebd4-41ce-9193-758e150b7017",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['/SST'].attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14898e4-9a8f-4729-b667-f1c87e79fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['/SST'].dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e510dc-0d98-4f77-a293-bceca001ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sst = dataset['SST'][0, 45:80, 45:125]\n",
    "print('Type of object: ', type(sst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbff112-6f62-4fb4-9d5c-7f3754188eea",
   "metadata": {},
   "source": [
    "###  old `DAP2` approach\n",
    "\n",
    "Below, we access the same dataset on the same server and request the DAP2 response. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f309df-f02f-49dc-8c0a-bb0f34dbac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = open_url('http://test.opendap.org/dap/data/nc/coads_climatology.nc') # dap2 is the default\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a4cdd6-fe57-4785-aaa3-c36e7d114f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af17034-55b1-43e9-b834-eabe5886161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst = dataset['SST'] # or dataset.SST\n",
    "sst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138342b6-ae77-4a4b-8010-9da278c0140e",
   "metadata": {},
   "source": [
    "Note that the variable is of type `GridType`, a multidimensional array with specific axes defining each of its dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb75ed2b-bbc7-4ba6-8768-bab3e2213f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst.dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d03e37-f9b3-475a-bcf4-3da398175d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7070cc-d080-48cf-a0cf-e28264484b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485110f5-3156-46a8-bd67-0638fd99a461",
   "metadata": {},
   "source": [
    "```{note}\n",
    "`len` and `shape` of `sst` differ! The difference between them is a property of the `GridType`: in this case `sst` packs with itself the `coordinate axes` necessary to be fully \"self-described\". This behavior was done to mimick the `netCDF` model, that each file (in this case each `gridded array`) is \"self-describing\" and therefore contains all the relevant information to process it. The `tree` view of the dataset above further illustrates the point, with the multiple copies of coordinate data in dataset. Everytime you download a `GridType` you also download the dimension arrays used fully describe them. \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "It is possible to specify NOT to download the coordinate axes of a `GridType` variable when opening a URL as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a42dc7c-fb37-43bd-92bd-45ef3d152b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = open_url(\"http://test.opendap.org/dap/data/nc/coads_climatology.nc\", output_grid=False)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbd60d2-b9d8-4eed-bacc-fa47e2959b65",
   "metadata": {},
   "source": [
    "NO data has been downloaded into memory yet, but when you download a `GridType` array, the coordinate axes will not be downloaded. This important workaround is particularly usefull for speeding up workflows, and to not overwhelm older `OPeNDAP` servers that might run out of memory when attempting to retrieve both the data and the coordinate axes of a variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd313ce-7f11-42e1-ba6a-2f3661595e56",
   "metadata": {},
   "source": [
    "\n",
    "```{note}\n",
    "The `GridType` is a `DAP2` model specification and was dropped in the much newer `DAP4`. Nonetheless, `OPeNDAP DAP4` servers support `DAP2`. Currently `PyDAP` when opening a remote URL, if `protocol` is not specified, `PyDAP` assumes by default the DAP2 model specification. This may change in the future.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8c5986-11d9-412b-afe8-e891199fe8c7",
   "metadata": {},
   "source": [
    "In `PyDAP`, the `BaseType` is a thin wrapper to a `numpy.ndarray` with some of the same basic attributes like shape, nbytes. The `Dap4BaseProxy` is an empty data container with all the attributes of the remote array, including:\n",
    "\n",
    "- `name`\n",
    "- `dtype`\n",
    "- `shape`\n",
    "- `slice`\n",
    "\n",
    "\n",
    "\n",
    "To `download` data into memory you must `slice` the array. This is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4905a44-c50f-420d-b649-bded449b52d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sst = dataset['SST']['SST'][:]\n",
    "print('Type of object: ', type(sst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9eabe9-dcb2-4fd8-8413-13b99422810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sst.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1da443c-e900-45fc-99dd-a5a24f96cabd",
   "metadata": {},
   "source": [
    "```{note}\n",
    "One of the features of OPeNDAP is the `server-side subsetting`, which can be exploited by `PyDAP` via slicing of the array when downloading data. For example, if you are only interested in a localized subregion of the entire domain (e.g. finite range of latitude and longitudes of the global coverage), and you know the index that span your desired area of interest. \n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e37ef3-8024-4d18-92d0-51820f2ecf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sst = dataset['SST'][0, 45:80, 45:125]\n",
    "print('Type of object: ', type(sst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe9bd01-67bb-442f-a9cf-cfc1c64743b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dadce7-9a4b-4ef9-bfeb-cdac15cbbfd1",
   "metadata": {},
   "source": [
    "```{note}\n",
    "The subsetting took place close to the data thanks for OPenDAP's server functionality, and only the data that we request in the slice, is downloaded. \n",
    "```\n",
    "\n",
    "```{note}\n",
    "Slicing the array before downloading will almost always result in better performance and speed ups. This can be significant for very large datasets, and particularly useful when automatizing workflows that require downloading data into memory for further processing.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1f7167-bac3-447b-ac53-7e4daf13c374",
   "metadata": {},
   "source": [
    "## Tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63463d5-201a-4661-b27e-5fecb2b2ddb0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let's look now at tabular data, which `PyDAP` calls them `Sequences` (typically asociated with Sequential in situ data). Here we consider another file from within the test OPeNDAP server for simplicity. You can access the catalog [HERE](http://test.opendap.org/opendap/hyrax/).\n",
    "\n",
    "```{note}\n",
    "Sequential data consists of one of more records of related variables, such as simultaneous measurements of temperature and wind velocity for example. \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63107649-1bae-4053-86c6-6c2f47f89db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = open_url(\"http://test.opendap.org/opendap/hyrax/data/ff/gsodock1.dat\")\n",
    "ds.tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984df51f-d3b6-49b2-9ed3-fb94a71a63b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['URI_GSO-Dock']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6480925-98d3-4df4-9511-ed8e8b6232b6",
   "metadata": {},
   "source": [
    "### ERDDAP in situ data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbcd6a6-c58b-427a-bb41-7d04282f0fc0",
   "metadata": {},
   "source": [
    "Consider a more complex example. Here we look at data from the [glider](https://oceanservice.noaa.gov/facts/ocean-gliders.html) DAC found at the [Integrated Ocean Observing System](https://data.ioos.us/organization/glider-dac) . The data can be accessed through an OPeNDAP server, as well as the [ERRDAP](https://gliders.ioos.us/erddap/index.html) server. In the example below we demostrate how to access glider data from a\n",
    "Deep-Pelagic Nekton study off the Gulf of Mexico, with pydap through `ERRDAP`.\n",
    "\n",
    "We look at the `Dataset ID: Murphy-20150809T1355`. It's `ERDDAP` access form can be found [HERE](https://gliders.ioos.us/erddap/tabledap/Murphy-20150809T1355.html?trajectory%2Cwmo_id%2Cprofile_id%2Ctime%2Clatitude%2Clongitude%2Cdepth%2Cconductivity%2Cconductivity_qc%2Cdensity%2Cdensity_qc%2Cdepth_qc%2Cinstrument_ctd%2Clat_qc%2Clat_uv%2Clat_uv_qc%2Clon_qc%2Clon_uv%2Clon_uv_qc%2Cplatform_meta%2Cprecise_lat%2Cprecise_lon%2Cprecise_time%2Cpressure%2Cpressure_qc%2Cprofile_lat_qc%2Cprofile_lon_qc%2Cprofile_time_qc%2Cqartod_conductivity_flat_line_flag%2Cqartod_conductivity_gross_range_flag%2Cqartod_conductivity_primary_flag%2Cqartod_conductivity_rate_of_change_flag%2Cqartod_conductivity_spike_flag%2Cqartod_density_flat_line_flag%2Cqartod_density_gross_range_flag%2Cqartod_density_primary_flag%2Cqartod_density_rate_of_change_flag%2Cqartod_density_spike_flag%2Cqartod_monotonic_pressure_flag%2Cqartod_pressure_flat_line_flag%2Cqartod_pressure_gross_range_flag%2Cqartod_pressure_primary_flag%2Cqartod_pressure_rate_of_change_flag%2Cqartod_pressure_spike_flag%2Cqartod_salinity_flat_line_flag%2Cqartod_salinity_gross_range_flag%2Cqartod_salinity_primary_flag%2Cqartod_salinity_rate_of_change_flag%2Cqartod_salinity_spike_flag%2Cqartod_temperature_flat_line_flag%2Cqartod_temperature_gross_range_flag%2Cqartod_temperature_primary_flag%2Cqartod_temperature_rate_of_change_flag%2Cqartod_temperature_spike_flag%2Csalinity%2Csalinity_qc%2Ctemperature%2Ctemperature_qc%2Ctime_qc%2Ctime_uv%2Ctime_uv_qc%2Cu%2Cu_qc%2Cv%2Cv_qc&time%3E=2015-08-12T00%3A00%3A00Z&time%3C=2015-08-19T22%3A10%3A22Z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1aa47e-d02c-4b9e-8380-ee269c3aa695",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = open_url(\"https://gliders.ioos.us/erddap/tabledap/Murphy-20150809T1355\")['s']\n",
    "ds.tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e62bc0b-1c83-46a7-b9af-160f667f5ee2",
   "metadata": {},
   "source": [
    "Where the variables `s` identifies the sequential data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8056936-ce83-4f04-89e7-5e8ee91278d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dbaba0-41ba-462e-8937-3e33e10741b2",
   "metadata": {},
   "source": [
    "We can further identify each individual glider data by looking at `profile_id`, a value that is unique for each of them. You can inspect the raw values are follows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da841aa7-a100-4bb7-8f33-d850da0bf640",
   "metadata": {},
   "outputs": [],
   "source": [
    "[id for id in ds['profile_id'].iterdata()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec1fd47-ca8b-4c55-8326-c2f88b228284",
   "metadata": {},
   "source": [
    "```{note}\n",
    "`OPeNDAP` and therefore `PyDAP` support fully-qualifying names, which come in handly for complex (nested) data structures. In the case of `Sequential` data, you can access a variable `<VarName>` within a sequence named `<Seq>` as `<Seq.VarName>`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff8ed82-9413-4d4f-ab6a-257360046c24",
   "metadata": {},
   "source": [
    "These datasets are rich in metadata, which can be accessed through the attributes property as follows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd3aec-a996-4de1-8112-ffc6a9ac052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['profile_id'].attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f1efa-1de8-42e9-908f-aa5fc8de8281",
   "metadata": {},
   "source": [
    "The first thing we\\'d like to do is limit our very simple analysis. We consider only a single glider and only inspect the variables `depth` and `temperature`. This is simlar to `column-wise selection`.\n",
    "\n",
    "\n",
    "To accomplish that we use pydap\\'s simple logic as follows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094458a0-a7f9-4768-bdde-bbd36014b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = ds[('profile_id', 'depth', 'temperature')]\n",
    "print(type(seq))\n",
    "seq.tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9421d280-291d-4ca2-b78d-84f9c71897ae",
   "metadata": {},
   "source": [
    "### Filtering data\n",
    "\n",
    "With `Sequential`  data we can make use of `filters` to extract only those values associated with one or more `rows`. This is, identify all the values of the sequence that are less than, equal to, or greater than. \n",
    "\n",
    "For example, lets consider `depth` and `temperature` values associated with the value `profile_id=5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1461aa2-e437-4b38-8f8e-1496dd1e3c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "glid5 = seq[('profile_id', 'depth', 'temperature')][seq['profile_id'].data==5]\n",
    "glid5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4bdd5b-f248-4d1b-872e-d05451a965a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Depths5 = np.array([depth for depth in glid5['depth']])\n",
    "ids5 = np.array([_id for _id in glid5['profile_id']])\n",
    "Temps5 = np.array([temp for temp in glid5['temperature']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c03f4d-71d3-4e92-9d9c-f927127bc094",
   "metadata": {},
   "source": [
    "Lets try another `profile_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5945b81-fd27-4f8d-a1e0-670ecc09520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "glid6 = seq[('profile_id', 'depth', 'temperature')][seq['profile_id'].data==6]\n",
    "Depths6 = np.array([depth for depth in glid6['depth']])\n",
    "ids6 = np.array([_id for _id in glid6['profile_id']])\n",
    "Temps6 = np.array([temp for temp in glid6['temperature']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad69f458-3185-4cb2-8481-ec35097d22f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Temps5, -Depths5, ls='', marker='o', markersize=10, alpha=0.5, label='profile id: ' +str(ids5[0]))\n",
    "plt.plot(Temps6, -Depths6, 'k', ls='', marker='d', markersize=10, alpha=0.25, label='profile id: ' +str(ids6[0]))\n",
    "plt.xlabel(r'$\\text{Temp} \\;[^\\circ C]$', fontsize=12.5)\n",
    "plt.ylabel(r'$Z\\;[m]$', fontsize=12.5, rotation=0, labelpad=10)\n",
    "plt.legend(fontsize=12.5, frameon=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa4609e-1343-4e1f-a045-3c6ee6b6feba",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "**Basic and Digest**\n",
    "\n",
    "To use `Basic` and `Digest` authentication, simply add your username and password to the dataset URL. Keep in mind that if the server only supports Basic authentication your credentials will be sent as plaintext, and could be sniffed on the network.\n",
    "\n",
    "```{code}\n",
    "dataset = open_url('http://username:password@server.example.com/path/to/dataset')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f9f0fd-a205-4618-bff9-b98098f5a8d8",
   "metadata": {},
   "source": [
    "### CAS\n",
    "\n",
    "The [Central Authentication Service](http://en.wikipedia.org/wiki/Central_Authentication_Service) (`CAS`) is a single sign-on protocol for the web, usually involving a web browser and cookies. Nevertheless it\\'s possible to use pydap with an OPeNDAP server behind a CAS. The function `install_cas_client` below\n",
    "replaces pydap\\'s default HTTP function with a new version able to submit authentication data to an HTML form and store credentials in cookies. (In this particular case, the server uses Javascript to redirect the browser to a new location, so the client has to parse the location from the Javascript code; other CAS would require a tweaked function.)\n",
    "\n",
    "To use it, just attach a web browsing `session` with authentication cookies:\n",
    "\n",
    "```{code}\n",
    "from pydap.client import open_url\n",
    "from pydap.cas.get_cookies import setup_session\n",
    "session = setup_session(authentication_url, username, password)\n",
    "dataset = open_url('http://server.example.com/path/to/dataset', session=session)\n",
    "```\n",
    "\n",
    "This method could work but each CAS is slightly different and might require a specifically designed `setup_session` instance. Two CAS are however explicitly supported by `PyDAP`:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d91dca0-cc58-43d1-b7b5-61184c7a8230",
   "metadata": {},
   "source": [
    "###  URS NASA EARTHDATA\n",
    "\n",
    "```{note}\n",
    "This method requires an EDL account. If you do not have one, go [HERE](https://urs.earthdata.nasa.gov/home) to create one\n",
    "```\n",
    "\n",
    "Authentication can done through a `username` and a `password`. However, it is `highly recommended` to use instead `tokens`. This [ECCO](.notebooks/ECCO) provides an example of how to use tokens to authenticate. \n",
    "\n",
    "```{code}\n",
    "edl_token = \"YourTokenHere\"\n",
    "auth_hdr=\"Bearer \" + edl_token\n",
    "my_session = requests.Session()\n",
    "my_session.headers={\"Authorization\": auth_hdr}\n",
    "```\n",
    "\n",
    "With that you can now pass the `my_session` as an argument to `PyDAP`'s `open_url`:\n",
    "```{code}\n",
    "dataset = open_url('http://server.example.com/path/to/dataset', session=my_session)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e842f3-4800-4b21-aff0-4e008c857367",
   "metadata": {},
   "source": [
    "### Earth System Grid Federation (ESGF)\n",
    "\n",
    "Authentication is done through an `openid` and a `password`:\n",
    "\n",
    "```{code}\n",
    "from pydap.client import open_url\n",
    "from pydap.cas.esgf import setup_session\n",
    "dataset_url = 'http://server.example.com/path/to/dataset'\n",
    "session = setup_session(openid, password, check_url=dataset_url)\n",
    "dataset = open_url(dataset_url, session=session)\n",
    "```\n",
    "\n",
    "If your `openid` contains contains the string `ceda.ac.uk`\n",
    "authentication requires an additional `username` argument:\n",
    "\n",
    "```{code}\n",
    "from pydap.client import open_url\n",
    "from pydap.cas.esgf import setup_session\n",
    "session = setup_session(openid, password, check_url=dataset_url, username=username)\n",
    "dataset = open_url(dataset_url, session=session)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4102d1a6-c548-4deb-bc22-2e148e36d1df",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "All Advanced features described below may be outdated.\n",
    "```\n",
    "\n",
    "### Advanced features\n",
    "\n",
    "**Calling server-side functions**\n",
    "\n",
    "When you open a remote dataset, the `DatasetType` object has a special\n",
    "attribute named `functions` that can be used to invoke any server-side\n",
    "functions. Here\\'s an example of using the `geogrid` function from\n",
    "Hyrax:\n",
    "\n",
    "```{code}\n",
    ">>> dataset = open_url(\"http://test.opendap.org/dap/data/nc/coads_climatology.nc\")\n",
    ">>> new_dataset = dataset.functions.geogrid(dataset.SST, 10, 20, -10,60)\n",
    ">>> new_dataset.SST.COADSY[:] \n",
    "[-11. -9. -7. -5. -3. -1. 1. 3. 5. 7. 9. 11.]\n",
    ">>> new_dataset.SST.COADSX[:]\n",
    "[ 21. 23. 25. 27. 29. 31. 33. 35. 37. 39. 41. 43. 45. 47. 49. 51. 53. 55. 57. 59. 61.]\n",
    "```\n",
    "\n",
    "Unfortunately, there\\'s currently no standard mechanism to discover which functions the server support. The `function` attribute will accept\n",
    "any function name the user specifies, and will try to pass the call to the remote server.\n",
    "\n",
    "\n",
    "### Using a cache\n",
    "```{warning}\n",
    "This may be outdated.\n",
    "```\n",
    "\n",
    "You can specify a cache directory in the `pydap.lib.CACHE` global variable. If this value is different than `None`, the client will try\n",
    "(if the server headers don\\'t prohibit) to cache the result, so repeated\n",
    "requests will be read from disk instead of the network:\n",
    "\n",
    "```{code}\n",
    "import pydap.lib\n",
    "pydap.lib.CACHE = \"/tmp/pydap-cache/\"\n",
    "```\n",
    "\n",
    "### Timeout\n",
    "\n",
    "To specify a timeout for the client, just set the desired number of seconds using the `timeout` option to `open_url(...)` or `open_dods(...)`. For example, the following commands would timeout after 30 seconds without receiving a response from the server:\n",
    "\n",
    "```{code}\n",
    "dataset = open_url('http://test.opendap.org/dap/data/nc/coads_climatology.nc', timeout=30)\n",
    "dataset = open_dods('http://test.opendap.org/dap/data/nc/coads_climatology.nc.dods', timeout=30)\n",
    "```\n",
    "\n",
    "### Configuring a proxy\n",
    "```{warning}\n",
    "This may be outdated.\n",
    "```\n",
    "It\\'s possible to configure pydap to access the network through a proxy\n",
    "server. Here\\'s an example for an HTTP proxy running on `localhost`\n",
    "listening on port 8000:\n",
    "\n",
    "```{code}\n",
    "import httplib2\n",
    "from pydap.util import socks\n",
    "import pydap.lib\n",
    "pydap.lib.PROXY = httplib2.ProxyInfo(\n",
    "         socks.PROXY_TYPE_HTTP, 'localhost', 8000)\n",
    "```\n",
    "\n",
    "This way, all further calls to `pydap.client.open_url` will be routed through the proxy server. You can also authenticate to the proxy:\n",
    "\n",
    "```{code}\n",
    "pydap.lib.PROXY = httplib2.ProxyInfo(\n",
    "         socks.PROXY_TYPE_HTTP, 'localhost', 8000,\n",
    "         proxy_user=USERNAME, proxy_pass=PASSWORD)\n",
    "```\n",
    "\n",
    "A user [has reported](http://groups.google.com/group/pydap/browse_thread/thread/425b2e1a3b3f233d) that `httplib2` has problems authenticating against a NTLM proxy server. In this case, a simple solution is to change the `pydap.http.request` function to use `urllib2` instead of `httplib2`, monkeypatching the code\n",
    "like in the [CAS authentication example above](#cas):\n",
    "\n",
    "```{code}\n",
    "import urllib2\n",
    "import logging\n",
    "\n",
    "def install_urllib2_client():\n",
    "    def new_request(url):\n",
    "        log = logging.getLogger('pydap')\n",
    "        log.INFO('Opening %s' % url)\n",
    "\n",
    "        f = urllib2.urlopen(url.rstrip('?&'))\n",
    "        headers = dict(f.info().items())\n",
    "        body = f.read()\n",
    "        return headers, body\n",
    "\n",
    "    from pydap.util import http\n",
    "    http.request = new_request\n",
    "```\n",
    "\n",
    "The function `install_urllib2_client` should then be called before doing any requests.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
