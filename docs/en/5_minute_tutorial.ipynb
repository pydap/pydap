{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cdc24e9-f0de-4820-871e-cea5bdbb9a73",
   "metadata": {},
   "source": [
    "# 5 Minute Tutorial\n",
    "\n",
    "## OPeNDAP - the vision\n",
    "The original vision of [OPeNDAP](https://www.opendap.org/) ([Cornillion, et al 1993](https://zenodo.org/records/10610992)) was democratize remote data access, by making the equivalency:\n",
    "\n",
    "$ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\boxed{\\text{URL} \\approx \\text{Remote Dataset} }$\n",
    "and\n",
    "$ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\boxed{\\text{URL + Constraints} \\approx \\text{Subset of Remote Dataset}} $\n",
    "\n",
    "That lead to the development of the `DAP2` protocol (formerly known as `DODS`). Currently, <span style='color:#ff6666'>**OPeNDAP**<span style='color:black'> and Unidata servers implement the <span style='color:#0066cc'>**DAP4**<span style='color:black'> protocol, which is more modern and broader in scope, to continue enabling the original vision of OPeNDAP.\n",
    "\n",
    "## What pydap enables:\n",
    "\n",
    "The internal logic of `PyDAP` enables the construction of constraint expressions for each url, realizing the original vision of <span style='color:#ff6666'>**OPeNDAP**<span style='color:black'> above, and given that `PyDAP` is a [backend engine](https://docs.xarray.dev/en/stable/user-guide/io.html#opendap) for `Xarray`, the original vision can scaled with parallelism. However, basic understanding of the use of Constraint Expression comes in handy when aggregating multiple files, for downloading only a handful of variables.\n",
    "\n",
    "\n",
    "### Objectives:\n",
    "\n",
    "\n",
    "- Demonstrate how to use the <span style='color:#0066cc'>**DAP4**<span style='color:black'> protocol.\n",
    "- Use Xarray with pydap as the back `Pydap` to download data from two remote sources: `a)` an `NcML` aggregation, and `b)` two individual files,.\n",
    "- Demonstrate the use of Constraint Expression and how these are passed down to the remote server so that <span style='color:#0066cc'>**subsetting is done by the server**<span style='color:black'> protocol\n",
    "\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- Datasets behind a <span style='color:#0066cc'>**DAP4**<span style='color:black'> implementing server. For example, the test server: http://test.opendap.org/opendap/\n",
    "- pydap>=3.5.8\n",
    "- xarray>=2025.0\n",
    "- numpy>=2.0\n",
    "\n",
    "Here, we demonstrate this. The remote dataset that will be used in this tutorial can be inspected via the browser [HERE](http://test.opendap.org:8080/opendap/tutorials/20220531090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc.dmr.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db3dfb-0d2d-4bab-8b50-864bfc7602dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydap.client import open_url, consolidate_metadata, create_session\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed50c2be-d275-4bcd-a056-e4f3fb615e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a session to inspect downloads. cache_name must have `debug`\n",
    "session = create_session(use_cache=True, cache_kwargs={\"cache_name\":'debug_case1'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b757b8-b7b6-455f-a3dd-de21e0a776a6",
   "metadata": {},
   "source": [
    "## Case 1) Subsetting an NcML file\n",
    "\n",
    "The file is an NcML file representing a virtually aggregated dataset, which can be found in the test server and it is named: [aggExisting.ncml](http://test.opendap.org/opendap/data/ncml/agg/aggExisting.ncml.dmr.html).\n",
    "\n",
    "`NcML` represent virtually aggregated individual NetCDF files, and OPeNDAP servers can be configured to produce these. With an individual opendap url, a user has access to an entire collection of files, from which to subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8e6360-9c42-4ee7-8af6-3df567ae70c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncml_url = \"http://test.opendap.org/opendap/data/ncml/agg/aggExisting.ncml\"\n",
    "dap4_ncml_url = ncml_url.replace(\"http\",  \"dap4\")\n",
    "print(\"=============================================================\\n Remote DAP4 URL: \\n\", dap4_ncml_url, \"\\n=============================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca76d28e-7b1e-4390-999c-6397b169c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\n",
    "    dap4_ncml_url, \n",
    "    engine='pydap',\n",
    "    session = session,\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5a5e44-957c-481a-a950-76d8338a3097",
   "metadata": {},
   "source": [
    "### What happens if we download a single data point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ce8fc-d936-4749-a3ff-e076c2a5e27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['T']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f1eae-dbc7-4ee8-872a-a209666ee7e3",
   "metadata": {},
   "source": [
    "```{note}\n",
    "The chunking of `T` implies the entire array is a single chunk! This is a stardard interpretation that `Xarray` makes of `OPeNDAP` urls. What happens if I download a simple subset? \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72184e94-7e56-4028-b737-b23f6d674164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the cache to inspect what is being downloaded\n",
    "session.cache.clear() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33924d0b-a2ce-4ce5-a85e-c9f42290f459",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds['T'].isel(time=1, lon=0).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48720cc8-ce67-449d-9578-f6578794ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"====================================== \\n Request sent to the Remote Server:\\n \", session.cache.urls()[0].split(\"?\")[-1].split(\"&dap4.checksum\")[0].replace(\"%5B\",\"[\").replace(\"%5D\",\"]\").replace(\"%3A\",\":\").replace(\"%2F\",\"/\"), \"\\n====================================== \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cef4e30-9d94-4d93-a303-6ec4718e574a",
   "metadata": {},
   "source": [
    "The constraint expression is built from the `.isel` Xarray method and passed to the server, which does all the work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5697eb49-ffdd-45b3-9825-f4b8b28fa7d3",
   "metadata": {},
   "source": [
    "## Case 2) Subsetting across two separate files.\n",
    "\n",
    "The two files can be found in the test server, named: [coads_climatology](http://test.opendap.org/opendap/data/nc/coads_climatology.nc.dmr.html) and [coads_climatology2](http://test.opendap.org/opendap/data/nc/coads_climatology.nc.dmr.html). These two datasets share identical spatial dimensions, can be aggregated in time, and share almost all identical variables.\n",
    "\n",
    "```{note}\n",
    "It is important to always check of datasets can be aggregated. `PyDAP` and `Xarray` have internal logic to check if any two or more datasets can be concatenated. But all these safety checks only take into account dimensions and cooordinates.\n",
    "```\n",
    "\n",
    "An important step will be the use or Constraint Expressions to ensure that only the same variables of interest are concatenating.\n",
    "\n",
    "```{warning}\n",
    "One of these files has extra variables that we will discarded by the use of CEs.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eedc2d6-23de-42af-a6b4-5789244e8c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\"http://test.opendap.org/opendap/data/nc/coads_climatology.nc\", \"http://test.opendap.org/opendap/data/nc/coads_climatology2.nc\"]\n",
    "dap4_urls = [url.replace(\"http\",\"dap4\") for url in urls]\n",
    "\n",
    "# constraint expression\n",
    "dap4_CE = \"?dap4.ce=\" + \";\".join([\"/SST\", \"/COADSX\", \"/COADSY\", \"/TIME\"])\n",
    "\n",
    "# Final list of OPeNDAP URLs\n",
    "dap4ce_urls =[url+dap4_CE for url in dap4_urls]\n",
    "print(\"====================================================\\nThe following are the DAP4 OPeNDAP URLs \\n\", dap4ce_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe51afda-0757-4a46-9b11-9c0999640842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192f21d0-7ddb-4fb0-a222-afebcbb31ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidate_metadata(dap4ce_urls, session=session, concat_dim=\"TIME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec4831-377b-4bb3-afdb-43564db1ad44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ab0d52d-7c64-4689-be0f-a8caf70e0cb4",
   "metadata": {},
   "source": [
    "```{note}\n",
    "`consolidate_metadata(dap4_urls, concat_dim='...', session=session)` downloads the dimensions of the remote file and stores them as a SQLite, to be reused. The session object becomes a get to authenticate, and a database manager! This practice can result in a performance gain of ~ 10-100 times faster workflows!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12184166-a4d7-4d80-86fe-e0838c4c13c0",
   "metadata": {},
   "source": [
    "### User xarray logic to download data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ef5ba-b1d4-4459-9f22-5b5dd027412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_mfdataset(\n",
    "    dap4ce_urls, \n",
    "    engine='pydap',\n",
    "    concat_dim='TIME',\n",
    "    session=session,\n",
    "    combine=\"nested\",\n",
    "    parallel=True,\n",
    "    decode_times=False,\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ecc7c2-c907-4d6f-b4ea-90a8f5a38e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['SST']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ba5656-bdcf-4e03-84e0-f28c777064dc",
   "metadata": {},
   "source": [
    "```{note}\n",
    "The chunking of `SST` implies the entire array is a single chunk! This is a stardard interpretation that `Xarray` makes of `OPeNDAP` urls. What if we download a single spatial point?\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414053a8-a9ef-4c98-8d0e-23d974bc430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.cache.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbfa280-b88f-4c53-816e-3ef912cb78e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds['SST'].isel(TIME=0, COADSX=0, COADSY=0).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89aa6d0-0ce7-4c6d-9c57-104d52e510b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"====================================== \\n Request sent to the Remote Server:\\n \", session.cache.urls()[0].split(\"?\")[-1].split(\"&dap4.checksum\")[0].replace(\"%5B\",\"[\").replace(\"%5D\",\"]\").replace(\"%3A\",\":\").replace(\"%2F\",\"/\"), \"\\n====================================== \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904266d8-9879-4820-977d-df57127e9c17",
   "metadata": {},
   "source": [
    "### The entire variable is unnecessarily downloaded !!\n",
    "\n",
    "Ideally we would want the see the following Request (in the constraint expressssion) sent to the Remote Server:\n",
    "\n",
    "```python\n",
    "dap4.ce=/SST[0][0][0]\n",
    "```\n",
    "It seems that `xr.open_mfdataset` does not pass the slice argument to the server for each remote dataset. Instead it downloads all the data in a single request, subsets it, and then aggregated the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8342eca8-65b2-4a2b-a67e-84b4807dc7bc",
   "metadata": {},
   "source": [
    "### How to send the slice to the Remote Server:\n",
    "\n",
    "\n",
    "The answer is, to `rechunk` the dataset when creating it. The chunk **should match the expected size of your subset**. That way, for remote file, the subset will be processed within a single requests.\n",
    "\n",
    "```{warning}\n",
    "If you chunk the dataset with a size smaller that your expected download, you will trigger many downloads per remote file, forcing `Xarray` extra work to assemble the data together.\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd373db5-e924-4144-8d4b-bd0766e0aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidate_metadata(dap4ce_urls, session=session, concat_dim=\"TIME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b168b04a-444f-48cd-9b00-35e4189fe920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a single element in all dimensions, the expected size is all unity\n",
    "expected_sizes = {\"TIME\":1, \"COADSX\":1, \"COADSY\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0851c1-db8b-492b-8b4d-d84ce8342ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds = xr.open_mfdataset(\n",
    "    dap4ce_urls, \n",
    "    engine='pydap',\n",
    "    concat_dim='TIME',\n",
    "    session=session,\n",
    "    combine=\"nested\",\n",
    "    parallel=True,\n",
    "    decode_times=False,\n",
    "    chunks=expected_sizes,\n",
    ")\n",
    "session.cache.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e94c77e-1231-4e25-83d0-7025f9156de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['SST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18783b1-f637-48ce-b3ec-6505d6ebc2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds['SST'].isel(TIME=0, COADSX=0, COADSY=0).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df444a09-b572-4a0c-ad83-0d90b68ee25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"====================================== \\n Request sent to the Remote Server:\\n \", session.cache.urls()[0].split(\"?\")[-1].split(\"&dap4.checksum\")[0].replace(\"%5B\",\"[\").replace(\"%5D\",\"]\").replace(\"%3A\",\":\").replace(\"%2F\",\"/\"), \"\\n====================================== \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6ca435-ee8f-44d7-b52f-b57c9142c2c6",
   "metadata": {},
   "source": [
    "### Warning: Be cautious about chunking\n",
    "\n",
    "We now only downloaded exactly what we requested! However, the time for download was 10x slower, compared to the case when we requested more data!! The reason for the slowdown can be attributed to the number of chunks the dask graph generated.\n",
    "\n",
    "\n",
    "* `No chunking. Download all the array in the file. 2 chunks in 5 dask graphs (one per file).`\n",
    "* `Chunking. Download only the desired element of a file. 388800 chunks in 5 dask graphs`. \n",
    "\n",
    "\n",
    "In the scenario above, we went to the extremes. It is better to find a chunk compromise. We demonstrate that below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef6b080-799d-49bf-a3ae-05f519e72fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidate_metadata(dap4ce_urls, session=session, concat_dim=\"TIME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4425e89-df96-46fa-9117-5d3a9ffa8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_sizes = {\"TIME\":1, \"COADSY\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf4b0a-6ac2-4e69-8d5d-25ed5f453092",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds = xr.open_mfdataset(\n",
    "    dap4ce_urls, \n",
    "    engine='pydap',\n",
    "    concat_dim='TIME',\n",
    "    session=session,\n",
    "    combine=\"nested\",\n",
    "    parallel=True,\n",
    "    decode_times=False,\n",
    "    chunks=download_sizes,\n",
    ")\n",
    "session.cache.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eae400-2227-4681-968e-35959f930584",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['SST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5cf1b7-5f15-4b86-ba10-4fd3a163e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds['SST'].isel(TIME=0, COADSX=0, COADSY=0).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849fe1ad-078a-4a76-b5f4-dca23b57c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"====================================== \\n Request sent to the Remote Server:\\n \", session.cache.urls()[0].split(\"?\")[-1].split(\"&dap4.checksum\")[0].replace(\"%5B\",\"[\").replace(\"%5D\",\"]\").replace(\"%3A\",\":\").replace(\"%2F\",\"/\"), \"\\n====================================== \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0752c6a-a804-41a1-b9d4-ef755a12c089",
   "metadata": {},
   "source": [
    "### Success! Similar timings but much and smaller download!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cca12b-d12a-4c45-a6d1-4f2256a73a10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
