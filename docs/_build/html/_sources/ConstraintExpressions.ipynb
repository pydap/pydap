{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b975993-c044-43ae-af7f-29ae6e5f0901",
   "metadata": {},
   "source": [
    "# Constraint Expressions: Server-side Subsetting\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Many OPeNDAP servers contain collections of datasets that in aggregation describe a complete dataset (e.g. a multi-year simulation). In some cases, each dataset may contain $\\sim O(10-100)$ of variables in them -- this is particularly true for Level 2 data, see for example [this ATLAS03 dataset](http://test.opendap.org:8080/opendap/atlas03/ATL03_20200131234815_05540602_003_01.h5.dmr.html) from NASA. This means PyDAP must parse 100s of variables per file. PyDAP is a fast parser of *DMRs* (the [DAP4 metadata](https://opendap.github.io/dap4-specification/DAP4.html#_dmr_declarations) response), but:\n",
    "\n",
    "1. PyDAP does not (yet) aggregate datasets nor URLs.\n",
    "2. PyDAP does not make CF-checks, nor does it define label-based operations.\n",
    "\n",
    "`xarray`, on the other hand, allows for parallel read and aggregation of multiple datasets. However, despite the awesome parallel features of `xarray`, it can be slow during the aggregation of multiple datasets because it performs a number of checks on the metadata so that the collection of files are \"safe\" to open and operate upon, according to the internal logics of `xarray`. This means that xarray makes extra checks to ensure safe label-based operations, and the time it takes can grow with the number of variables.\n",
    "\n",
    "```{note}\n",
    "Even though `xarray` hasa. method to drop variables from the virtual `xarray.Dataset`, it is only available **after** the dataset is created. This is, if you have 100s of files each with 100s of variables, but you are only interested in 2-3 variables per file, the client must parse and check all variables in all files, to create a dataset from which you will then drop all but the 2-3 variables of interest.\n",
    "```\n",
    "\n",
    "These, in combination, provide an obstacle for initial data exploration of collections of OPeNDAP datasets that contain many `variables`, `Groups`, among other complex types.\n",
    "\n",
    "\n",
    "## Approach\n",
    "\n",
    "One can add `Constraint Expresions` (`CEs`) to the dataset URL and sent it to the remote OPeNDAP server, to:\n",
    "\n",
    "1. Request a subset of variables, and\n",
    "2. Request a spatial subset of variables.\n",
    "\n",
    "\n",
    "These `CEs` are increadible powerful from the user perspective because `pydap`, as a backend engine to `xarray`, can receive a much smaller DAP response from the remote OPeNDAP server. This is, the `CEs inform the remote OPeNDAP server to subset close to the data`. The response may be faster by $\\sim O(1)$ second overall, but when considering a 100s of URLs, the result can have a significant impact on the performance and user experience.\n",
    "\n",
    "\n",
    "Below we review `Constraint Expressions` with real data on OPeNDAP servers. Because there are two distinct DAP Protocols (see [Pydap as a client](client)), we will review the two cases separately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4661fa0-e892-4c7a-ab5b-3861f26fc15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydap.client import open_url\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff075cc-f01a-4bf7-855e-3e975600d10d",
   "metadata": {},
   "source": [
    "## Constraint Expressions in DAP4\n",
    "\n",
    "Here we demonstrate the use of CE in arrays of 1 and 2 dimensions, in two distinct datasets:\n",
    "\n",
    "1. [ATLAS03](http://test.opendap.org:8080/opendap/atlas03/ATL03_20200131234815_05540602_003_01.h5.dmr.html), level 2 Data.\n",
    "2. [Daily MUR Sea Surface Temperature](http://test.opendap.org:8080/opendap/ghrsst/20210102090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.h5.dmr), level 4 data provided by PODAAC at JPL.\n",
    "\n",
    "\n",
    "```{note}\n",
    "For more interesting examples, take a look at [PACE example](notebooks/PACE)\n",
    "```\n",
    "\n",
    "### ATLAS03\n",
    "\n",
    "This dataset has many nested Groups, with many variables in them. Say we are only interested in the variables:\n",
    "\n",
    "1. `delta_time`.\n",
    "2. `lat_ph`.\n",
    "3. `lon_ph`.\n",
    "\n",
    "The tree variables lie within the Group `heights`, which in turn is nested in the `Group` with name `gt3r`. \n",
    "\n",
    "Lets open the remote file naively, by requesting all the variables from the OPeNDAP server ([Hyrax](https://www.opendap.org/software/hyrax-data-server/) in this case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c8f072-a8e4-4654-874c-67d43d15efcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'http://test.opendap.org:8080/opendap/atlas03/ATL03_20200131234815_05540602_003_01.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd1816-5122-4311-9b75-527badd9b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds = open_url(data_url, protocol='dap4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622162d3-24c1-4e04-adf7-d9b8c71206b6",
   "metadata": {},
   "source": [
    "Below, we print the entire tree directory within the HDF5 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8615944-cab3-4673-872a-6b3bb8cfd2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987ff46d-69c9-4a44-b72d-e0a8ace184fa",
   "metadata": {},
   "source": [
    "We must note that the same variable names appear in other groups across the file, in the different other `Groups`. \n",
    "\n",
    "The DAP4 Protocol makes it easier to identify each variable defined within a `Group` with a unique [Fully Qualyfying Name](https://opendap.github.io/dap4-specification/DAP4.html#_fully_qualified_names). In this case, the FQN of each variable, similar to the navigating thgrough file system is:\n",
    "\n",
    "| VarName | FQN_VarName |\n",
    "| :- | -: | \n",
    "| `delta_time` | `/gt3r/heights/delta_time` |\n",
    "| `lat_ph` | `/gt3r/heights/lat_ph` |\n",
    "| `lon_ph` | `/gt3r/heights/lon_ph` |\n",
    "\n",
    "\n",
    "With this knowledge, we want to only request these variables from the server's _DMR_. The DAP4 specirication for Constraint Expressions is:\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Data_url + ?dap4.ce=<FQN_VarName1>;<FQN_VarName2>;<FQN_VarName3> }\n",
    "$$\n",
    "\n",
    "Let's try it now:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3aa340-66c0-4945-8866-0eee303f8249",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_urlCE = data_url+'?dap4.ce=/gt3r/heights/delta_time;/gt3r/heights/lat_ph;/gt3r/heights/lon_ph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8317b4d-7bc4-49db-b8e5-651e2952b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds = open_url(data_urlCE, protocol='dap4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e16e5c-1f74-4158-b789-33db7594acfa",
   "metadata": {},
   "source": [
    "### This is an order of magnitude faster than before!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e10f138-59c5-4175-aef8-6b7d3dcf73f4",
   "metadata": {},
   "source": [
    "Because `Groups` are NOT part of the DAP2 data model, we cannot illustrate the CE in DAP2 with the `ATLAS03` dataset. Instead, we now look at the `COADS` dataset which has 2D arrays.\n",
    "\n",
    "\n",
    "\n",
    "## Spatial Subsetting\n",
    "Continuing to demonstrate `CEs` in the DAP4 data model, we now want to request only a subset of the variables. We first take a look at the complete dataset \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4aad07-fb7a-4a56-a06c-b080024e8528",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_url = 'http://test.opendap.org:8080/opendap/ghrsst/20210102090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda6ebf0-0c65-4a3f-972d-15a9a6a5d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds = open_url(data_url, protocol='dap4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e2068b-584b-4c2c-9ad2-fe7fcfed7496",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d265584-277b-4c09-9c37-f1b890a230df",
   "metadata": {},
   "source": [
    "Same as before in the DAP4 data model, we have\n",
    "\n",
    "| VarName | FQN_VarName |\n",
    "| :- | -: | \n",
    "| `time` | `/time` |\n",
    "| `lat` | `/lat` |\n",
    "| `lon` | `/lon` |\n",
    "| `mask` | `/mask` |\n",
    "| `sea_ice_fraction` | `/sea_ice_fraction` |\n",
    "| `dt_1km_data` | `/dt_1km_data` |\n",
    "| `analysed_sst` | `/analysed_sst` |\n",
    "| `analysis_error` | `/analysis_error` |\n",
    "| `sst_anomaly` | `/sst_anomaly` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ab2577-2b11-4e0e-8fc2-5cbedd224974",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['analysed_sst'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342aba5f-a7d6-428d-87ff-49985b855e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['analysed_sst'].attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f47ceb-6589-46f9-b0e3-b5966e8afc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dimensions of variable:', ds['analysed_sst'].dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a29356-664f-46b2-92b8-32600170638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df1b9e3-c16b-43dc-92b0-7807213bb846",
   "metadata": {},
   "source": [
    "We see that the variable has three dimensions, and these happen to coincide with those entire dataset.\n",
    "\n",
    "### Spatial Subset\n",
    "\n",
    "`We have yet to download/retrieve any data`. Only the _DMR_ has so far been requested by PyDAP. Consider the scenario where we only want to inspect a spatial subset of the data, defined by the `indexes ranges` aka `hyperslabs`. \n",
    "\n",
    "Say we want to retrieve only the first 100 points of `lat`, and the last 300 points of `lon`, of all variables in the dataset. In DAP4, there are two options to accomplish this with the URL.\n",
    "\n",
    "\n",
    "\n",
    "1. `Traditional Approach`. Define the hyperslab for each variable you request. The [Data Request Form](http://test.opendap.org:8080/opendap/ghrsst/20210102090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.h5.dmr) allows users to (interactively) build such URLS (by selecting boxes and modifying hyperslabs). Following this approach, you get the following Constrained URL\n",
    "\n",
    "```\n",
    "data_url + ?dap4.ce=/time;/lat[0:1:100];/lon[35700:1:];/mask[0][0:1:100][35700:1:];/sea_ice_fraction[0][0:1:100][35700:1:];/dt_1km_data[0][0:1:100][35700:1:];/analysed_sst[0][0:1:100][35700:1:];/analysed_sst[0][0:1:100][35700:1:];/analysis_error[0][0:1:100][35700:1:];/sst_anomaly[0][0:1:100][35700:1:]\n",
    "```\n",
    "\n",
    "Lets try it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf664a-d5f4-4163-a3ba-933a73ee1828",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nds = open_url(data_url+'?dap4.ce=/time[0];/lat[0:1:300];/lon[35699:1:35999];/mask[0][0:1:300][35699:1:35999];/sea_ice_fraction[0][0:1:300][35699:1:35999];/dt_1km_data[0][0:1:300][35699:1:35999];/analysed_sst[0][0:1:300][35699:1:35999];/analysis_error[0][0:1:300][35699:1:35999];/sst_anomaly[0][0:1:300][35699:1:35999]', protocol='dap4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd119170-0839-43f1-b7c7-25dbf6bf4d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "nds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acb19ec-0ffe-45f1-af34-a71c5a5a6807",
   "metadata": {},
   "outputs": [],
   "source": [
    "nds['/analysed_sst'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5746e72d-9b12-44c1-943c-b6c51cf4c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nds['/lon'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9674b4-b188-410e-81c7-3bda92d018ae",
   "metadata": {},
   "source": [
    "The spatial subsetting described above worked fine. It is very verbose and you have to explicitely set the size of all variables, if you want the resulting\n",
    "subset dataset to be self-consistent. For example, it can be easy to define the spatial subset only on a variable and not the rest.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a25ba-ef50-4901-bf8e-7a5f5ce38d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nds = open_url(data_url+'?dap4.ce=/time;/lat;/lon;/mask;/sea_ice_fraction;/dt_1km_data;/analysed_sst[0][0:1:300][35699:1:35999]', protocol='dap4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57c211-d531-45a3-bdea-1678c46bdec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nds['lat'].shape != nds['analysed_sst'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33604aa1-5f87-450a-9678-86da1a1e8bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nds['lat'].shape, nds['analysed_sst'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf2975d-3b81-4b8a-85fe-e3fae2627b21",
   "metadata": {},
   "source": [
    "Next we provide an alternative approach that is less error prone, and makes use of [Shared Dimensions](https://opendap.github.io/dap4-specification/DAP4.html#_subsetting_and_shared_dimensions).\n",
    "\n",
    "2. `Shared Dimensions`: This alternative approach can be used to define the spatial subsetting via the dimensions. The syntax is:\n",
    "\n",
    "```\n",
    "data_url + ?dap4.ce=<FQN_Dim1>=[subset];<FQN_Dim2>=[subset];<FQN_Var1>;<FQN_Var3>;<FQN_Var3>;...<FQN_VarN>\n",
    "```\n",
    "\n",
    "Where `<FQN_Var1>` may be the same as `<FQN_Dim1>`. \n",
    "\n",
    "In the syntax above, \n",
    "\n",
    "a) The subset is first defined on the dimensions by the `=` signs. Dimensions may be Global (at the root level), or within a `Group`. \n",
    "\n",
    "b) The user then defines the variables ot be included in the request by PyDAP. The subset defined in the previous space will be applied to the variable.\n",
    "\n",
    "\n",
    "\n",
    "Using the example, the much simplified URL becomes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec31b0-665b-4994-812c-67fcd03e422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nds = open_url(data_url+\"?dap4.ce=/lat=[0:1:300];/lon=[35699:1:35999];/time;/lat;/lon;/mask;/sea_ice_fraction;/dt_1km_data;/analysed_sst;/analysis_error;/sst_anomaly\", protocol='dap4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfac76e-21cb-4e9e-bb2b-a11036fb183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nds.tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c5e1a-f837-4712-8aa0-f0b047ceb391",
   "metadata": {},
   "outputs": [],
   "source": [
    "nds['/analysed_sst'].shape == nds['sst_anomaly'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
